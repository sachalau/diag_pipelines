rule create_snpEff_config_file:
    output:
        config_file = "references/{reference}/snpEff/snpEff.config",
    shell:
        """
        echo "codon.Bacterial_and_Plant_Plastid : TTT/F, TTC/F, TTA/L, TTG/L+, TCT/S, TCC/S, TCA/S, TCG/S, TAT/Y, TAC/Y, TAA/*, TAG/*, TGT/C, TGC/C, TGA/*, TGG/W, CTT/L, CTC/L, CTA/L, CTG/L+, CCT/P, CCC/P, CCA/P, CCG/P, CAT/H, CAC/H, CAA/Q, CAG/Q, CGT/R, CGC/R, CGA/R, CGG/R, ATT/I+, ATC/I+, ATA/I+, ATG/M+, ACT/T, ACC/T, ACA/T, ACG/T, AAT/N, AAC/N, AAA/K, AAG/K, AGT/S, AGC/S, AGA/R, AGG/R, GTT/V, GTC/V, GTA/V, GTG/V+, GCT/A, GCC/A, GCA/A, GCG/A, GAT/D, GAC/D, GAA/E, GAG/E, GGT/G, GGC/G, GGA/G, GGG/G" > {output[config_file]}
        echo "{wildcards.reference}.genome: H37Rv" >> {output[config_file]}
        echo "{wildcards.reference}.chromosomes: {wildcards.reference}" >> {output[config_file]}
        echo "{wildcards.reference}.{wildcards.reference}.codonTable: Bacterial_and_Plant_Plastid" >> {output[config_file]}
        """


rule link_files_for_snpEff_config:
    input:
        annotation = "references/{reference}/genome_fixed.gff",
        genome = "references/{reference}/genome_fasta.fasta",
    output:
        refseq = "references/{reference}/snpEff/data/{reference}/genes.gff",
        sequences = "references/{reference}/snpEff/data/{reference}/sequences.fa",
    shell:
        """
        cp {input[annotation]} {output[refseq]}
        cp {input[genome]} {output[sequences]}
        """


rule fix_gff_for_snpEff:
    input:
        gff = "{any_gff}.gff",
    output:
        gff_fixed = "{any_gff}_fixed.gff",
    run:
        from BCBio import GFF
        import Bio
        from Bio import SeqIO
        gff = GFF.parse(open(input["gff"]))
        for record in gff:
            for features in record.features:
                if features.type=="pseudogene":
                    if "gene" not in features.qualifiers:
                        features.qualifiers["gene"]=features.qualifiers["locus_tag"]
        GFF.write([record], open(output["gff_fixed"], "w"))
    

        
rule create_snpEff_database:
    conda:
        pipeline_path + "envs/snpEff.yml"
    input:
        gff = "references/{reference}/snpEff/data/{reference}/genes.gff",
        sequences = "references/{reference}/snpEff/data/{reference}/sequences.fa",
        config_file = "references/{reference}/snpEff/snpEff.config",
    output:
        predictor_bin = "references/{reference}/snpEff/data/{reference}/snpEffectPredictor.bin",
    shell:
        """
        snpEff build -gff3 -config {input[config_file]} {wildcards.reference}
        """
        
        

rule annotate_vcf_with_snpEff:
    conda:
        pipeline_path + "envs/snpEff.yml"
    input:
        vcf = "samples/{sample}/snps/{any_genotyper}/{reference}/{any_mapper}/{any_vcf}.vcf",
        predictor_bin = "references/{reference}/snpEff/data/{reference}/snpEffectPredictor.bin",
        config_file = "references/{reference}/snpEff/snpEff.config",
    output:
        annotated_vcf = temp("samples/{sample,[^/]+}/snps/{any_genotyper,[^/]+}/{reference,[^/]+}/{any_mapper,[^/]+}/{any_vcf}_snpEff.vcf")
    shell:
        """
        snpEff ann -upDownStreamLen 2000 -noStats -config {input[config_file]} -nodownload -ss 0 -spliceRegionExonSize 0 -spliceRegionIntronMax 0 -spliceRegionIntronMin 0 {wildcards.reference} {input[vcf]} > {output[annotated_vcf]}
        """

        
rule split_vcf:
    conda:
        pipeline_path + "envs/bcftools.yml",
    input:
        vcf = "{any_vcf}.vcf",
    output:
        vcf_split = temp("{any_vcf}_split.vcf"),
    shell:
        """
        bcftools norm --multiallelics - {input[vcf]} > {output[vcf_split]}
        """


        
rule format_vcf_before_loading_into_variant_table:
    conda:
        pipeline_path + "envs/snpEff.yml",
    input:
        vcf = "{any_vcf}.vcf.gz",
    output:
        vcf_formated = temp("{any_vcf}_formated_variant.tsv"),
    shell:
        """
        bcftools query -f "%CHROM\\t%POS\\t%REF\\t%ALT\\n" {input[vcf]} | awk '$4!="<NON_REF>"' > {output[vcf_formated]}
        """

        
rule format_vcf_before_loading_into_genotype_table:
    conda:
        pipeline_path + "envs/snpEff.yml",
    input:
        vcf = "{any_vcf}.vcf.gz",
    output:
        vcf_formated = temp("{any_vcf}_formated_genotype.tsv"),
    shell:
        """
        bcftools query -f "[%SAMPLE]\\t%CHROM\\t%POS\\t%REF\\t%ALT\\t%QUAL\\t[%AD]\\t[%DP]\\t%FILTER\\n" {input[vcf]} | awk '$5!="<NON_REF>"' > {output[vcf_formated]}
        """

        
rule extract_ANN_from_snpEff:
    conda:
        pipeline_path + "envs/bcftools.yml"
    input:
        vcf = "{any_vcf}_snpEff.vcf.gz",
    output:
        ann = temp("{any_vcf}_snpEff_ANN.tsv"),
    shell:
        """
        bcftools query -f "%CHROM %POS %REF %ALT %ANN\\n" {input[vcf]} > {output[ann]}
        """


rule format_snpEff_annotation_for_db:
    input:
        vcf = "{any_vcf}_snpEff_ANN.tsv",
    output:
        formated = temp("{any_vcf}_snpEff_db.tsv"),
    run:
        import pandas
        snpEff = pandas.read_csv(input["vcf"], sep=" ", names=["Chrom", "Pos", "Ref", "Alt","Annotation"], index_col=[0,1,2,3])["Annotation"].str.split(",", expand=True).stack().reset_index()[["Chrom", "Pos", "Ref", "Alt", 0]].set_index(["Chrom", "Pos", "Ref", "Alt"])[0].str.split("|", expand=True)
        snpEff.columns = ["Allele", "Annotation", "Putative_impact", "Gene_Name", "Gene_ID", "Feature_Type", "Feature_ID", "Transcript_biotype", "Rank", "HGVS.c", "HGVS.p", "cDNA_len", "CDS_len", "Protein_len", "Dist_to_feat", "Errors"]
        snpEff.pop("Rank")
        snpEff.to_csv(output["formated"], sep="\t", header=True, index=True, chunksize=500000)


rule extract_annotation_for_protein_change:
    input:
        formated = "{any_vcf}_snpEff_db.tsv",
    output:
        substitution = temp("{any_vcf}_snpEff_formated_protein_change.tsv"),
    run:
        import pandas, re
        snpEff = pandas.read_csv(input["formated"], sep="\t", header=0)
        regexp_simple_change={
            "missense":{
                'reg': r'p\.[A-Z][a-z]{2}\d+[A-Z][a-z]{2}',
                "sep": "\d+"
            },
            "silent":{
                'reg': r'p\.[A-Z][a-z]{2}\d+[A-Z][a-z]{2}',
                "sep": "\d+"
            },
            "start_lost":{
                'reg': r'^p\.[A-Z][a-z]{2}1\?$',
                "sep": "1"
            },
            "initiator_codon_variant":{
                "reg": r'^p\.[A-Z][a-z]{2}1\?$',
                "sep": "1"
            },
            "start_retained":{
                "reg": r'^p\.[A-Z][a-z]{2}1[A-Z][a-z]{2}$',
                "sep":"1"
             },
            "stop_lost":{
                'reg':r'^p\.Ter\d+(?:[A-Z][a-z]{2}ext\*\?|fs)$',
                "sep":"\d+"
            },
            "stop_gained":{
                'reg': r'p\.[A-Z][a-z]{2}\d+\*',
                "sep":"\d+"
            },
            "stop_retained":{
                "reg": r'^p\.Ter\d+Ter$',
                "sep": "\d+"
            }
        }
        regexp_frameshift_single_deletion_duplication={
            "frameshift":{
                "reg": r'^p\.[A-z][a-z]{2}\d+fs$',
                "sep": "\d+"
            },
            "deletion":{
                "reg": r'^p\.[A-z][a-z]{2}\d+del$',
                "sep": "\d+"
            },
            "duplication":{
                "reg": r'^p\.[A-z][a-z]{2}\d+dup$',
                "sep": "\d+"
            }
        }
        regexp_multi_deletion_duplication ={
            "deletion":{
                "reg": r'^p\.[A-z][a-z]{2}\d+_[A-z][a-z]{2}\d+del$',
                "sep": "_"
            },
            "duplication":{
                "reg": r'^p\.[A-z][a-z]{2}\d+_[A-z][a-z]{2}\d+dup$',
                "sep": "_"
            },
        }
        regexp_insertion_multi_delins={
            "insertion":
            {
                "reg": r'^p\.[A-z][a-z]{2}\d+_[A-z][a-z]{2}\d+ins(?:[A-Z][a-z]{2})+$',
                "sep": "_"
            },
            "deletion_insertion":{
                "reg": r'^p\.[A-z][a-z]{2}\d+_[A-z][a-z]{2}\d+delins(?:[A-Z][a-z]{2})+$',
                "sep": "_"
            }
        }
        regexp_single_delins={
            "deletion_insertion":
            {
                "reg": r'^p\.[A-z][a-z]{2}\d+delins(?:[A-Z][a-z]{2})+$',
                "sep": "_"
            }
        }
        final = pandas.DataFrame([])
        for annotation, values in regexp_simple_change.items():
            tmp = snpEff.loc[snpEff["HGVS.p"].str.match(values["reg"], na=False)]
            if not tmp.empty:
                tmp[["start_AA", "alt_AA"]] = tmp["HGVS.p"].str.replace("^p\.", "").str.split(pat=values["sep"], expand=True)
                tmp["start_pos"] = tmp["Protein_len"].str.split("/", expand=True)[0]
                if annotation=="missense":
                    tmp = tmp.loc[(tmp["start_AA"]!=tmp["alt_AA"]) & (tmp["start_pos"]!=1) & (tmp["start_AA"]!="Ter")]
                elif annotation=="silent":
                    tmp = tmp.loc[(tmp["start_AA"]==tmp["alt_AA"]) & (tmp["start_pos"]!=1) & (tmp["start_AA"]!="Ter")]
                elif annotation=="start_lost":
                    tmp = tmp.loc[(tmp["Annotation"]!="initiator_codon_variant")]
                elif annotation=="initiator_codon_variant":
                    tmp = tmp.loc[(tmp["Annotation"]!="start_lost")]
                tmp["type"] = annotation
                tmp["end_pos"] = tmp["start_pos"]
                tmp["insertion_length"] = 0
                tmp["end_AA"] = tmp["start_AA"]
                final = pandas.concat([final, tmp])
        for annotation, values in regexp_frameshift_single_deletion_duplication.items():
            tmp = snpEff.loc[snpEff["HGVS.p"].str.match(values["reg"], na=False)]
            if not tmp.empty:
                tmp["start_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.split(pat=values["sep"], expand=True)[0]
                tmp["start_pos"] = tmp["Protein_len"].str.split("/", expand=True)[0]
                tmp = tmp.loc[tmp["start_AA"]!="Ter"]
                tmp["type"] = annotation
                tmp["end_pos"] = tmp["start_pos"]
                tmp["alt_AA"] = ""
                tmp["insertion_length"] = 0
                tmp["end_AA"] = tmp["start_AA"]
                final = pandas.concat([final, tmp])
        for annotation, values in regexp_multi_deletion_duplication.items():
            tmp = snpEff.loc[snpEff["HGVS.p"].str.match(values["reg"], na=False)]
            if not tmp.empty:
                tmp["type"] = annotation
                tmp["start_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del", "").str.replace("dup", "").str.split(pat=values["sep"], expand=True)[0].str[:3]
                tmp["start_pos"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del", "").str.replace("dup", "").str.split(pat=values["sep"], expand=True)[0].str[3:]
                tmp["end_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del", "").str.replace("dup", "").str.split(pat=values["sep"], expand=True)[1].str[:3]
                tmp["end_pos"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del", "").str.replace("dup", "").str.split(pat=values["sep"], expand=True)[1].str[3:]
                tmp["alt_AA"] = ""
                tmp["insertion_length"] = 0
                final = pandas.concat([final, tmp])
        for annotation, values in regexp_insertion_multi_delins.items():
            tmp = snpEff.loc[snpEff["HGVS.p"].str.match(values["reg"], na=False)]
            if not tmp.empty:
                tmp["type"] = annotation
                tmp["start_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("ins", "").str.replace("del", "").str.split(pat=values["sep"], expand=True)[0].str[:3]
                tmp["start_pos"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del", "").str.replace("ins", "").str.split(pat=values["sep"], expand=True)[0].str[3:]
                tmp["end_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del.*", "").str.replace("ins.*", "").str.split(pat=values["sep"], expand=True)[1].str[:3]
                tmp["end_pos"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("del.*", "").str.replace("ins.*", "").str.split(pat=values["sep"], expand=True)[1].str[3:]
                tmp["alt_AA"] = tmp["HGVS.p"].str.split("ins", expand=True)[1]
                tmp["insertion_length"] = tmp["alt_AA"].str.len().divide(3)
                final = pandas.concat([final, tmp])
        for annotation, values in regexp_single_delins.items():
            tmp = snpEff.loc[snpEff["HGVS.p"].str.match(values["reg"], na=False)]
            if not tmp.empty:
                tmp["type"] = annotation
                tmp["start_AA"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("delins", "").str.split(pat=values["sep"], expand=True)[0].str[:3]
                tmp["start_pos"] = tmp["HGVS.p"].str.replace("^p\.", "").str.replace("delins.*", "").str.split(pat=values["sep"], expand=True)[0].str[3:]
                tmp["alt_AA"] = tmp["HGVS.p"].str.split("ins", expand=True)[1]
                tmp["insertion_length"] = tmp["alt_AA"].str.len().divide(3)
                tmp["end_pos"] = tmp["start_pos"]
                tmp["end_AA"] = tmp["start_AA"]
                final = pandas.concat([final, tmp])
        final["alt_AA"] = final["alt_AA"].str.replace("*", "Ter").str.replace("extTer\?", "")
        print(sum(final["type"].value_counts()))
        print(final["type"].value_counts())
        final.to_csv(output["substitution"], sep="\t", header=True, index=False)


 

        
        
#        re_missense = r'p\.[A-Z][a-z]{2}\d+[A-Z][a-z]{2}'
#        re_stop = r'p\.[A-Z][a-z]{2}\d+\*'
#        re_start_lost = r'p\.[A-Z][a-z]{2}1\?'
#        re_stop_lost =  r'p\.Ter\d+[A-Z][a-z]{2}ext\?*'
#        missense = snpEff.loc[snpEff["Annotation"]=="missense_variant"]
#        missense = missense.loc[missense["HGVS.p"].str.match(re_missense)]
#        missense[["referenceAA", "mutatedAA"]] = missense["HGVS.p"].str.replace("^p\.", "").str.split(pat="\d+", expand=True)#

#        stop_gained = snpEff.loc[snpEff["Annotation"]=="stop_gained"]
 #       stop_gained = stop_gained.loc[stop_gained["HGVS.p"].str.match(re_stop)]
  #      stop_gained[["referenceAA", "mutatedAA"]] = stop_gained["HGVS.p"].str.replace("^p\.", "").str.split(pat="\d+", expand=True)
   #     stop_gained[["position", "total_length"]] = stop_gained["Protein_len"].str.split("/", expand=True)
    #    stop_gained["mutatedAA"] = "Ter"
     #   start_lost = snpEff.loc[snpEff["Annotation"]=="start_lost"]
      #  start_lost = start_lost.loc[start_lost["HGVS.p"].str.match(re_start_lost)]
       # start_lost[["referenceAA", "mutatedAA"]] = start_lost["HGVS.p"].str.replace("^p\.", "").str.split(pat="1", expand=True)
     #   start_lost[["position", "total_length"]] = start_lost["Protein_len"].str.split("/", expand=True)
     #   missense[["Chrom", "Pos", "Ref", "Alt", "Gene_Name", "position", "referenceAA", "mutatedAA"]].to_csv(output["substitution"], sep="\t", header=True, index=False)
      #  stop_gained[["Chrom", "Pos", "Ref", "Alt", "Gene_Name", "position", "referenceAA", "mutatedAA"]].to_csv(output["substitution"], sep="\t", header=False, index=False, mode="a")
      #  start_lost[["Chrom", "Pos", "Ref", "Alt", "Gene_Name", "position", "referenceAA", "mutatedAA"]].to_csv(output["substitution"], sep="\t", header=False, index=False, mode="a")
        
        #        re_stop = r'p\.[A-Z][a-z]{2}\d+\*'
#        re_stop_lost = r'p\.Ter\d+[A-Z][a-z]{2}ext\?*'
#        re_frameshift = r'p\.[A-Z][a-z]{2}\d+fs'
#        re_start_lost = r'p\.Met1\?'
#        missense = snpEff.loc[snpEff["HGVS.p"].str.match(re_missense)]
#        stop = snpEff.loc[snpEff["HGVS.p"].str.match(re_stop)]
#        frameshift = snpEff.loc[snpEff["HGVS.p"].str.match(re_frameshift)]
#        missense[["referenceAA", "mutatedAA"]] = missense["HGVS.p"].str.replace("^p\.", "").str.split(pat="\d+", expand=True)
#        missense[["position", "total_length"]] = missense["Protein_len"].str.split("/", expand=True)
#        missense[["Feature_ID", "position", "referenceAA", "mutatedAA"]].to_csv(output["formated"], sep="\t", header=False, index=True)

#        substitution = snpEff.loc[snpEff["annotation"].isin(["missense_variant", "stop_gained", "start_lost", "stop_retained_variant", "stop_lost"])]
#        substitution[["Chrom", "Pos", "Ref", "Alt", .to_csv
                                  
