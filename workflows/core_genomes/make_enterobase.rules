import pandas

pipeline_path = workflow.basedir + "/../../"

include:
    pipeline_path + "workflows/logging.rules"
    
include:
    pipeline_path + "rules/downloading/fetch_single_reference.rules"
    
enterobase = pandas.read_csv(pipeline_path + "data/core_genome_dbs/enterobase_database.tsv", sep="\t", index_col=0)

rule get_schema_from_enterobase:
    params:
        enterobase_scheme = lambda wildcards: enterobase.loc[wildcards.spec, "Scheme"],
        enterobase_species_id = lambda wildcards: enterobase.loc[wildcards.spec, "SpeciesId"],
    output:
        gene_list = "core_genomes/cgMLST/{spec}/genes.txt",
    shell:
        """
        wget -qO- http://enterobase.warwick.ac.uk/download_data?allele=profiles\&scheme={params.enterobase_scheme}\&species={params.enterobase_species_id} | gzip -d | head -n 1 | tr '[:space:]' '\\n' | tail -n +2 > {output[gene_list]} || :
        """

rule fetch_gene_entries_from_locus_tag:
    conda:
        pipeline_path + "envs/biopython.yml"
    input:
        gbk = lambda wildcards : "references/" + str(enterobase.loc[wildcards.spec, "ReferenceGenome"]) + "/genome_gbwithparts.gbwithparts",
        locus_list = "core_genomes/cgMLST/{spec}/genes.txt",
    output:
        bed = "core_genomes/cgMLST/{spec}.bed",
        problematic = "core_genomes/cgMLST/{spec}/enterobase_missing.txt",
    script:
        pipeline_path + "rules/core_genome/scripts/parse_gff_extract_locus_tags.py"

